08:45:36 : Epoch[0] pretrain loss 3.9093 training acc 0.1473
08:45:37 : Epoch [1] with testing accuracy: 0.1549
08:45:37 : Epoch[1] pretrain loss 3.8632 training acc 0.1724
08:45:38 : Epoch [2] with testing accuracy: 0.1894
08:45:39 : Epoch[2] pretrain loss 3.6675 training acc 0.3513
08:45:39 : Epoch [3] with testing accuracy: 0.2158
08:45:40 : Epoch[3] pretrain loss 3.5181 training acc 0.4889
08:45:40 : Epoch [4] with testing accuracy: 0.2488
08:45:41 : Epoch[4] pretrain loss 3.4231 training acc 0.5714
08:45:41 : Epoch [5] with testing accuracy: 0.2510
08:45:42 : Epoch[5] pretrain loss 3.3821 training acc 0.5897
08:45:42 : Epoch [6] with testing accuracy: 0.2565
08:45:43 : Epoch[6] pretrain loss 3.3701 training acc 0.5911
08:45:43 : Epoch [7] with testing accuracy: 0.2541
08:45:44 : Epoch[7] pretrain loss 3.3646 training acc 0.5922
08:45:44 : Epoch [8] with testing accuracy: 0.2618
08:45:45 : Epoch[8] pretrain loss 3.3605 training acc 0.5936
08:45:46 : Epoch [9] with testing accuracy: 0.2593
08:45:47 : Epoch[9] pretrain loss 3.3588 training acc 0.5941
08:45:47 : Epoch [10] with testing accuracy: 0.2669
08:45:48 : Epoch[10] pretrain loss 3.3573 training acc 0.5943
08:45:48 : Epoch [11] with testing accuracy: 0.2658
08:45:49 : Epoch[11] pretrain loss 3.3528 training acc 0.6000
08:45:49 : Epoch [12] with testing accuracy: 0.2655
08:45:50 : Epoch[12] pretrain loss 3.3398 training acc 0.6156
08:45:50 : Epoch [13] with testing accuracy: 0.2744
08:45:51 : Epoch[13] pretrain loss 3.3348 training acc 0.6177
08:45:51 : Epoch [14] with testing accuracy: 0.2764
08:45:52 : Epoch[14] pretrain loss 3.3330 training acc 0.6182
08:45:53 : Epoch [15] with testing accuracy: 0.2750
08:45:53 : Epoch[15] pretrain loss 3.3317 training acc 0.6187
08:45:54 : Epoch [16] with testing accuracy: 0.2754
08:45:55 : Epoch[16] pretrain loss 3.3306 training acc 0.6193
08:45:55 : Epoch [17] with testing accuracy: 0.2789
08:45:56 : Epoch[17] pretrain loss 3.3294 training acc 0.6201
08:45:56 : Epoch [18] with testing accuracy: 0.2721
08:45:57 : Epoch[18] pretrain loss 3.3182 training acc 0.6324
08:45:57 : Epoch [19] with testing accuracy: 0.2723
08:45:58 : Epoch[19] pretrain loss 3.3100 training acc 0.6407
08:45:58 : Epoch [20] with testing accuracy: 0.2459
08:45:59 : Epoch[20] pretrain loss 3.2928 training acc 0.6608
08:46:00 : Epoch [21] with testing accuracy: 0.2622
08:46:00 : Epoch[21] pretrain loss 3.2888 training acc 0.6625
08:46:01 : Epoch [22] with testing accuracy: 0.2611
08:46:02 : Epoch[22] pretrain loss 3.2874 training acc 0.6628
08:46:02 : Epoch [23] with testing accuracy: 0.2783
08:46:03 : Epoch[23] pretrain loss 3.2787 training acc 0.6728
08:46:03 : Epoch [24] with testing accuracy: 0.2648
08:46:04 : Epoch[24] pretrain loss 3.2649 training acc 0.6872
08:46:04 : Epoch [25] with testing accuracy: 0.2578
08:46:05 : Epoch[25] pretrain loss 3.2621 training acc 0.6890
08:46:05 : Epoch [26] with testing accuracy: 0.2663
08:46:06 : Epoch[26] pretrain loss 3.2615 training acc 0.6891
08:46:06 : Epoch [27] with testing accuracy: 0.2750
08:46:07 : Epoch[27] pretrain loss 3.2599 training acc 0.6902
08:46:07 : Epoch [28] with testing accuracy: 0.2588
08:46:08 : Epoch[28] pretrain loss 3.2599 training acc 0.6899
08:46:09 : Epoch [29] with testing accuracy: 0.2576
08:46:09 : Epoch[29] pretrain loss 3.2589 training acc 0.6905
08:46:10 : Epoch [30] with testing accuracy: 0.2601
08:46:11 : Epoch[30] pretrain loss 3.2580 training acc 0.6910
08:46:11 : Epoch [31] with testing accuracy: 0.2649
08:46:12 : Epoch[31] pretrain loss 3.2573 training acc 0.6916
08:46:12 : Epoch [32] with testing accuracy: 0.2688
08:46:13 : Epoch[32] pretrain loss 3.2574 training acc 0.6914
08:46:13 : Epoch [33] with testing accuracy: 0.2538
08:46:14 : Epoch[33] pretrain loss 3.2562 training acc 0.6925
08:46:14 : Epoch [34] with testing accuracy: 0.2755
08:46:15 : Epoch[34] pretrain loss 3.2564 training acc 0.6919
08:46:15 : Epoch [35] with testing accuracy: 0.2661
08:46:16 : Epoch[35] pretrain loss 3.2557 training acc 0.6927
08:46:17 : Epoch [36] with testing accuracy: 0.2624
08:46:17 : Epoch[36] pretrain loss 3.2557 training acc 0.6924
08:46:18 : Epoch [37] with testing accuracy: 0.2618
08:46:19 : Epoch[37] pretrain loss 3.2553 training acc 0.6927
08:46:19 : Epoch [38] with testing accuracy: 0.2562
08:46:20 : Epoch[38] pretrain loss 3.2543 training acc 0.6934
08:46:20 : Epoch [39] with testing accuracy: 0.2516
08:46:21 : Epoch[39] pretrain loss 3.2390 training acc 0.7118
08:46:21 : Epoch [40] with testing accuracy: 0.2536
08:46:22 : Epoch[40] pretrain loss 3.2351 training acc 0.7145
08:46:22 : Epoch [41] with testing accuracy: 0.2534
08:46:23 : Epoch[41] pretrain loss 3.2339 training acc 0.7153
08:46:24 : Epoch [42] with testing accuracy: 0.2530
08:46:25 : Epoch[42] pretrain loss 3.2336 training acc 0.7149
08:46:25 : Epoch [43] with testing accuracy: 0.2540
08:46:26 : Epoch[43] pretrain loss 3.2331 training acc 0.7154
08:46:26 : Epoch [44] with testing accuracy: 0.2673
08:46:27 : Epoch[44] pretrain loss 3.2323 training acc 0.7160
08:46:27 : Epoch [45] with testing accuracy: 0.2535
08:46:28 : Epoch[45] pretrain loss 3.2323 training acc 0.7158
08:46:28 : Epoch [46] with testing accuracy: 0.2592
08:46:29 : Epoch[46] pretrain loss 3.2313 training acc 0.7166
08:46:30 : Epoch [47] with testing accuracy: 0.2533
08:46:31 : Epoch[47] pretrain loss 3.2319 training acc 0.7157
08:46:31 : Epoch [48] with testing accuracy: 0.2563
08:46:32 : Epoch[48] pretrain loss 3.2310 training acc 0.7167
08:46:32 : Epoch [49] with testing accuracy: 0.2591
08:46:33 : Epoch[49] pretrain loss 3.2310 training acc 0.7164
08:46:33 : Epoch [50] with testing accuracy: 0.2569
08:46:34 : Epoch[50] pretrain loss 3.2306 training acc 0.7168
08:46:34 : Epoch [51] with testing accuracy: 0.2645
08:46:35 : Epoch[51] pretrain loss 3.2298 training acc 0.7175
08:46:36 : Epoch [52] with testing accuracy: 0.2579
08:46:36 : Epoch[52] pretrain loss 3.2298 training acc 0.7175
08:46:37 : Epoch [53] with testing accuracy: 0.2572
08:46:38 : Epoch[53] pretrain loss 3.2299 training acc 0.7171
08:46:38 : Epoch [54] with testing accuracy: 0.2581
08:46:39 : Epoch[54] pretrain loss 3.2299 training acc 0.7171
08:46:39 : Epoch [55] with testing accuracy: 0.2509
08:46:40 : Epoch[55] pretrain loss 3.2293 training acc 0.7177
08:46:40 : Epoch [56] with testing accuracy: 0.2546
08:46:41 : Epoch[56] pretrain loss 3.2291 training acc 0.7178
08:46:41 : Epoch [57] with testing accuracy: 0.2597
08:46:42 : Epoch[57] pretrain loss 3.2291 training acc 0.7176
08:46:42 : Epoch [58] with testing accuracy: 0.2601
08:46:43 : Epoch[58] pretrain loss 3.2291 training acc 0.7177
08:46:43 : Epoch [59] with testing accuracy: 0.2557
08:46:44 : Epoch[59] pretrain loss 3.2291 training acc 0.7175
08:46:45 : Epoch [60] with testing accuracy: 0.2601
08:46:46 : Epoch[60] pretrain loss 3.2291 training acc 0.7174
08:46:46 : Epoch [61] with testing accuracy: 0.2578
08:46:47 : Epoch[61] pretrain loss 3.2286 training acc 0.7178
08:46:47 : Epoch [62] with testing accuracy: 0.2581
08:46:48 : Epoch[62] pretrain loss 3.2287 training acc 0.7177
08:46:48 : Epoch [63] with testing accuracy: 0.2529
08:46:49 : Epoch[63] pretrain loss 3.2281 training acc 0.7184
08:46:49 : Epoch [64] with testing accuracy: 0.2574
08:46:50 : Epoch[64] pretrain loss 3.2282 training acc 0.7182
08:46:50 : Epoch [65] with testing accuracy: 0.2560
08:46:51 : Epoch[65] pretrain loss 3.2282 training acc 0.7180
08:46:51 : Epoch [66] with testing accuracy: 0.2563
08:46:52 : Epoch[66] pretrain loss 3.2281 training acc 0.7182
08:46:53 : Epoch [67] with testing accuracy: 0.2581
08:46:53 : Epoch[67] pretrain loss 3.2282 training acc 0.7181
08:46:54 : Epoch [68] with testing accuracy: 0.2594
08:46:55 : Epoch[68] pretrain loss 3.2277 training acc 0.7184
08:46:55 : Epoch [69] with testing accuracy: 0.2631
08:46:56 : Epoch[69] pretrain loss 3.2275 training acc 0.7187
08:46:56 : Epoch [70] with testing accuracy: 0.2612
08:46:57 : Epoch[70] pretrain loss 3.2275 training acc 0.7187
08:46:57 : Epoch [71] with testing accuracy: 0.2564
08:46:58 : Epoch[71] pretrain loss 3.2277 training acc 0.7184
08:46:58 : Epoch [72] with testing accuracy: 0.2596
08:46:59 : Epoch[72] pretrain loss 3.2274 training acc 0.7186
08:47:00 : Epoch [73] with testing accuracy: 0.2553
08:47:01 : Epoch[73] pretrain loss 3.2274 training acc 0.7185
08:47:01 : Epoch [74] with testing accuracy: 0.2565
08:47:02 : Epoch[74] pretrain loss 3.2273 training acc 0.7186
08:47:02 : Epoch [75] with testing accuracy: 0.2569
08:47:03 : Epoch[75] pretrain loss 3.2266 training acc 0.7194
08:47:03 : Epoch [76] with testing accuracy: 0.2564
08:47:04 : Epoch[76] pretrain loss 3.2262 training acc 0.7197
08:47:04 : Epoch [77] with testing accuracy: 0.2593
08:47:05 : Epoch[77] pretrain loss 3.2268 training acc 0.7190
08:47:05 : Epoch [78] with testing accuracy: 0.2549
08:47:06 : Epoch[78] pretrain loss 3.2270 training acc 0.7187
08:47:07 : Epoch [79] with testing accuracy: 0.2477
08:47:07 : Epoch[79] pretrain loss 3.2263 training acc 0.7195
08:47:08 : Epoch [80] with testing accuracy: 0.2445
08:47:09 : Epoch[80] pretrain loss 3.2267 training acc 0.7190
08:47:09 : Epoch [81] with testing accuracy: 0.2594
08:47:10 : Epoch[81] pretrain loss 3.2260 training acc 0.7197
08:47:10 : Epoch [82] with testing accuracy: 0.2548
08:47:11 : Epoch[82] pretrain loss 3.2263 training acc 0.7194
08:47:11 : Epoch [83] with testing accuracy: 0.2605
08:47:12 : Epoch[83] pretrain loss 3.2261 training acc 0.7195
08:47:12 : Epoch [84] with testing accuracy: 0.2544
08:47:13 : Epoch[84] pretrain loss 3.2260 training acc 0.7195
08:47:14 : Epoch [85] with testing accuracy: 0.2584
08:47:14 : Epoch[85] pretrain loss 3.2258 training acc 0.7198
08:47:15 : Epoch [86] with testing accuracy: 0.2592
08:47:16 : Epoch[86] pretrain loss 3.2262 training acc 0.7193
08:47:16 : Epoch [87] with testing accuracy: 0.2577
08:47:17 : Epoch[87] pretrain loss 3.2265 training acc 0.7191
08:47:17 : Epoch [88] with testing accuracy: 0.2593
08:47:18 : Epoch[88] pretrain loss 3.2259 training acc 0.7196
08:47:18 : Epoch [89] with testing accuracy: 0.2584
08:47:19 : Epoch[89] pretrain loss 3.2261 training acc 0.7194
08:47:19 : Epoch [90] with testing accuracy: 0.2578
08:47:20 : Epoch[90] pretrain loss 3.2263 training acc 0.7191
08:47:20 : Epoch [91] with testing accuracy: 0.2416
08:47:21 : Epoch[91] pretrain loss 3.2260 training acc 0.7194
08:47:22 : Epoch [92] with testing accuracy: 0.2586
08:47:23 : Epoch[92] pretrain loss 3.2257 training acc 0.7196
08:47:23 : Epoch [93] with testing accuracy: 0.2482
08:47:24 : Epoch[93] pretrain loss 3.2254 training acc 0.7198
08:47:24 : Epoch [94] with testing accuracy: 0.2551
08:47:25 : Epoch[94] pretrain loss 3.2256 training acc 0.7197
08:47:25 : Epoch [95] with testing accuracy: 0.2424
08:47:26 : Epoch[95] pretrain loss 3.2259 training acc 0.7193
08:47:26 : Epoch [96] with testing accuracy: 0.2515
08:47:27 : Epoch[96] pretrain loss 3.2260 training acc 0.7193
08:47:27 : Epoch [97] with testing accuracy: 0.2425
08:47:28 : Epoch[97] pretrain loss 3.2259 training acc 0.7194
08:47:29 : Epoch [98] with testing accuracy: 0.2438
08:47:30 : Epoch[98] pretrain loss 3.2199 training acc 0.7268
08:47:30 : Epoch [99] with testing accuracy: 0.2295
08:47:31 : Epoch[99] pretrain loss 3.2132 training acc 0.7339
08:47:31 : Epoch [100] with testing accuracy: 0.2340
