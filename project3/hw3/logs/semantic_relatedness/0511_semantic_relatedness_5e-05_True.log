08:41:34 : Epoch[0] pretrain loss 3.7928 training acc 0.2438
08:41:35 : Epoch [1] with testing accuracy: 0.2368
08:41:36 : Epoch[1] pretrain loss 3.3985 training acc 0.5820
08:41:36 : Epoch [2] with testing accuracy: 0.2581
08:41:37 : Epoch[2] pretrain loss 3.3394 training acc 0.6136
08:41:37 : Epoch [3] with testing accuracy: 0.2578
08:41:38 : Epoch[3] pretrain loss 3.3306 training acc 0.6189
08:41:38 : Epoch [4] with testing accuracy: 0.2822
08:41:39 : Epoch[4] pretrain loss 3.3210 training acc 0.6283
08:41:39 : Epoch [5] with testing accuracy: 0.2669
08:41:40 : Epoch[5] pretrain loss 3.2966 training acc 0.6541
08:41:41 : Epoch [6] with testing accuracy: 0.2733
08:41:42 : Epoch[6] pretrain loss 3.2823 training acc 0.6671
08:41:42 : Epoch [7] with testing accuracy: 0.2391
08:41:43 : Epoch[7] pretrain loss 3.2563 training acc 0.6941
08:41:43 : Epoch [8] with testing accuracy: 0.2689
08:41:44 : Epoch[8] pretrain loss 3.2512 training acc 0.6975
08:41:44 : Epoch [9] with testing accuracy: 0.2640
08:41:45 : Epoch[9] pretrain loss 3.2382 training acc 0.7105
08:41:45 : Epoch [10] with testing accuracy: 0.2478
08:41:46 : Epoch[10] pretrain loss 3.2123 training acc 0.7377
08:41:46 : Epoch [11] with testing accuracy: 0.2651
08:41:47 : Epoch[11] pretrain loss 3.2073 training acc 0.7416
08:41:47 : Epoch [12] with testing accuracy: 0.2673
08:41:48 : Epoch[12] pretrain loss 3.2050 training acc 0.7435
08:41:49 : Epoch [13] with testing accuracy: 0.2498
08:41:49 : Epoch[13] pretrain loss 3.2031 training acc 0.7445
08:41:50 : Epoch [14] with testing accuracy: 0.2607
08:41:51 : Epoch[14] pretrain loss 3.2022 training acc 0.7453
08:41:51 : Epoch [15] with testing accuracy: 0.2472
08:41:52 : Epoch[15] pretrain loss 3.2019 training acc 0.7454
08:41:52 : Epoch [16] with testing accuracy: 0.2458
08:41:53 : Epoch[16] pretrain loss 3.2008 training acc 0.7462
08:41:53 : Epoch [17] with testing accuracy: 0.2261
08:41:54 : Epoch[17] pretrain loss 3.2004 training acc 0.7467
08:41:54 : Epoch [18] with testing accuracy: 0.2457
08:41:55 : Epoch[18] pretrain loss 3.1995 training acc 0.7470
08:41:55 : Epoch [19] with testing accuracy: 0.2455
08:41:56 : Epoch[19] pretrain loss 3.1986 training acc 0.7478
08:41:57 : Epoch [20] with testing accuracy: 0.2486
08:41:58 : Epoch[20] pretrain loss 3.1985 training acc 0.7476
08:41:58 : Epoch [21] with testing accuracy: 0.2419
08:41:59 : Epoch[21] pretrain loss 3.1984 training acc 0.7476
08:41:59 : Epoch [22] with testing accuracy: 0.2357
08:42:00 : Epoch[22] pretrain loss 3.1979 training acc 0.7480
08:42:00 : Epoch [23] with testing accuracy: 0.2583
08:42:01 : Epoch[23] pretrain loss 3.1979 training acc 0.7481
08:42:02 : Epoch [24] with testing accuracy: 0.2510
08:42:03 : Epoch[24] pretrain loss 3.1975 training acc 0.7486
08:42:03 : Epoch [25] with testing accuracy: 0.2458
08:42:04 : Epoch[25] pretrain loss 3.1968 training acc 0.7490
08:42:04 : Epoch [26] with testing accuracy: 0.2433
08:42:05 : Epoch[26] pretrain loss 3.1971 training acc 0.7487
08:42:05 : Epoch [27] with testing accuracy: 0.2376
08:42:06 : Epoch[27] pretrain loss 3.1962 training acc 0.7494
08:42:07 : Epoch [28] with testing accuracy: 0.2453
08:42:08 : Epoch[28] pretrain loss 3.1968 training acc 0.7488
08:42:08 : Epoch [29] with testing accuracy: 0.2405
08:42:09 : Epoch[29] pretrain loss 3.1963 training acc 0.7492
08:42:09 : Epoch [30] with testing accuracy: 0.2476
08:42:10 : Epoch[30] pretrain loss 3.1963 training acc 0.7492
08:42:10 : Epoch [31] with testing accuracy: 0.2378
08:42:11 : Epoch[31] pretrain loss 3.1959 training acc 0.7496
08:42:11 : Epoch [32] with testing accuracy: 0.2452
08:42:12 : Epoch[32] pretrain loss 3.1963 training acc 0.7491
08:42:13 : Epoch [33] with testing accuracy: 0.2267
08:42:14 : Epoch[33] pretrain loss 3.1951 training acc 0.7501
08:42:14 : Epoch [34] with testing accuracy: 0.2400
08:42:15 : Epoch[34] pretrain loss 3.1955 training acc 0.7498
08:42:15 : Epoch [35] with testing accuracy: 0.2440
08:42:16 : Epoch[35] pretrain loss 3.1952 training acc 0.7499
08:42:16 : Epoch [36] with testing accuracy: 0.2429
08:42:17 : Epoch[36] pretrain loss 3.1956 training acc 0.7495
08:42:18 : Epoch [37] with testing accuracy: 0.2449
08:42:19 : Epoch[37] pretrain loss 3.1953 training acc 0.7499
08:42:19 : Epoch [38] with testing accuracy: 0.2299
08:42:20 : Epoch[38] pretrain loss 3.1955 training acc 0.7498
08:42:20 : Epoch [39] with testing accuracy: 0.2430
08:42:21 : Epoch[39] pretrain loss 3.1955 training acc 0.7497
08:42:21 : Epoch [40] with testing accuracy: 0.2433
08:42:22 : Epoch[40] pretrain loss 3.1954 training acc 0.7497
08:42:22 : Epoch [41] with testing accuracy: 0.2488
08:42:23 : Epoch[41] pretrain loss 3.1951 training acc 0.7499
08:42:24 : Epoch [42] with testing accuracy: 0.2535
08:42:25 : Epoch[42] pretrain loss 3.1954 training acc 0.7496
08:42:25 : Epoch [43] with testing accuracy: 0.2430
08:42:26 : Epoch[43] pretrain loss 3.1950 training acc 0.7500
08:42:26 : Epoch [44] with testing accuracy: 0.2453
08:42:27 : Epoch[44] pretrain loss 3.1952 training acc 0.7498
08:42:27 : Epoch [45] with testing accuracy: 0.2433
08:42:28 : Epoch[45] pretrain loss 3.1953 training acc 0.7497
08:42:28 : Epoch [46] with testing accuracy: 0.2453
08:42:29 : Epoch[46] pretrain loss 3.1948 training acc 0.7501
08:42:30 : Epoch [47] with testing accuracy: 0.2498
08:42:31 : Epoch[47] pretrain loss 3.1957 training acc 0.7492
08:42:31 : Epoch [48] with testing accuracy: 0.2458
08:42:32 : Epoch[48] pretrain loss 3.1950 training acc 0.7499
08:42:32 : Epoch [49] with testing accuracy: 0.2448
08:42:33 : Epoch[49] pretrain loss 3.1950 training acc 0.7499
08:42:33 : Epoch [50] with testing accuracy: 0.2503
08:42:34 : Epoch[50] pretrain loss 3.1952 training acc 0.7496
08:42:34 : Epoch [51] with testing accuracy: 0.2506
08:42:35 : Epoch[51] pretrain loss 3.1945 training acc 0.7505
08:42:36 : Epoch [52] with testing accuracy: 0.2564
08:42:37 : Epoch[52] pretrain loss 3.1955 training acc 0.7496
08:42:37 : Epoch [53] with testing accuracy: 0.2363
08:42:38 : Epoch[53] pretrain loss 3.1956 training acc 0.7495
08:42:38 : Epoch [54] with testing accuracy: 0.2578
08:42:39 : Epoch[54] pretrain loss 3.1898 training acc 0.7560
08:42:39 : Epoch [55] with testing accuracy: 0.2391
08:42:40 : Epoch[55] pretrain loss 3.1757 training acc 0.7708
08:42:40 : Epoch [56] with testing accuracy: 0.2431
08:42:41 : Epoch[56] pretrain loss 3.1647 training acc 0.7824
08:42:41 : Epoch [57] with testing accuracy: 0.2210
08:42:42 : Epoch[57] pretrain loss 3.1586 training acc 0.7876
08:42:43 : Epoch [58] with testing accuracy: 0.2346
08:42:44 : Epoch[58] pretrain loss 3.1566 training acc 0.7897
08:42:44 : Epoch [59] with testing accuracy: 0.2406
08:42:45 : Epoch[59] pretrain loss 3.1558 training acc 0.7900
08:42:45 : Epoch [60] with testing accuracy: 0.2239
08:42:46 : Epoch[60] pretrain loss 3.1556 training acc 0.7901
08:42:46 : Epoch [61] with testing accuracy: 0.2255
08:42:47 : Epoch[61] pretrain loss 3.1550 training acc 0.7907
08:42:47 : Epoch [62] with testing accuracy: 0.2344
08:42:48 : Epoch[62] pretrain loss 3.1549 training acc 0.7905
08:42:49 : Epoch [63] with testing accuracy: 0.2346
08:42:50 : Epoch[63] pretrain loss 3.1543 training acc 0.7910
08:42:50 : Epoch [64] with testing accuracy: 0.2383
08:42:51 : Epoch[64] pretrain loss 3.1544 training acc 0.7909
08:42:51 : Epoch [65] with testing accuracy: 0.2392
08:42:52 : Epoch[65] pretrain loss 3.1541 training acc 0.7911
08:42:52 : Epoch [66] with testing accuracy: 0.2357
08:42:53 : Epoch[66] pretrain loss 3.1540 training acc 0.7911
08:42:54 : Epoch [67] with testing accuracy: 0.2332
08:42:55 : Epoch[67] pretrain loss 3.1543 training acc 0.7908
08:42:55 : Epoch [68] with testing accuracy: 0.2391
08:42:56 : Epoch[68] pretrain loss 3.1542 training acc 0.7909
08:42:56 : Epoch [69] with testing accuracy: 0.2439
08:42:57 : Epoch[69] pretrain loss 3.1536 training acc 0.7915
08:42:57 : Epoch [70] with testing accuracy: 0.2376
08:42:58 : Epoch[70] pretrain loss 3.1538 training acc 0.7913
08:42:58 : Epoch [71] with testing accuracy: 0.2421
08:42:59 : Epoch[71] pretrain loss 3.1544 training acc 0.7907
08:43:00 : Epoch [72] with testing accuracy: 0.2342
08:43:01 : Epoch[72] pretrain loss 3.1539 training acc 0.7912
08:43:01 : Epoch [73] with testing accuracy: 0.2430
08:43:02 : Epoch[73] pretrain loss 3.1540 training acc 0.7910
08:43:02 : Epoch [74] with testing accuracy: 0.2462
08:43:03 : Epoch[74] pretrain loss 3.1537 training acc 0.7913
08:43:03 : Epoch [75] with testing accuracy: 0.2392
08:43:04 : Epoch[75] pretrain loss 3.1536 training acc 0.7915
08:43:04 : Epoch [76] with testing accuracy: 0.2471
08:43:05 : Epoch[76] pretrain loss 3.1531 training acc 0.7919
08:43:05 : Epoch [77] with testing accuracy: 0.2455
08:43:06 : Epoch[77] pretrain loss 3.1535 training acc 0.7914
08:43:07 : Epoch [78] with testing accuracy: 0.2495
08:43:08 : Epoch[78] pretrain loss 3.1540 training acc 0.7910
08:43:08 : Epoch [79] with testing accuracy: 0.2338
08:43:09 : Epoch[79] pretrain loss 3.1531 training acc 0.7919
08:43:09 : Epoch [80] with testing accuracy: 0.2376
08:43:10 : Epoch[80] pretrain loss 3.1538 training acc 0.7911
08:43:10 : Epoch [81] with testing accuracy: 0.2338
08:43:11 : Epoch[81] pretrain loss 3.1531 training acc 0.7918
08:43:11 : Epoch [82] with testing accuracy: 0.2351
08:43:12 : Epoch[82] pretrain loss 3.1535 training acc 0.7914
08:43:12 : Epoch [83] with testing accuracy: 0.2387
08:43:13 : Epoch[83] pretrain loss 3.1532 training acc 0.7916
08:43:14 : Epoch [84] with testing accuracy: 0.2407
08:43:15 : Epoch[84] pretrain loss 3.1532 training acc 0.7917
08:43:15 : Epoch [85] with testing accuracy: 0.2357
08:43:16 : Epoch[85] pretrain loss 3.1533 training acc 0.7915
08:43:16 : Epoch [86] with testing accuracy: 0.2373
08:43:17 : Epoch[86] pretrain loss 3.1516 training acc 0.7933
08:43:17 : Epoch [87] with testing accuracy: 0.2402
08:43:18 : Epoch[87] pretrain loss 3.1362 training acc 0.8105
08:43:18 : Epoch [88] with testing accuracy: 0.2511
08:43:19 : Epoch[88] pretrain loss 3.1338 training acc 0.8125
08:43:19 : Epoch [89] with testing accuracy: 0.2600
08:43:20 : Epoch[89] pretrain loss 3.1322 training acc 0.8138
08:43:21 : Epoch [90] with testing accuracy: 0.2418
08:43:22 : Epoch[90] pretrain loss 3.1327 training acc 0.8130
08:43:22 : Epoch [91] with testing accuracy: 0.2678
08:43:23 : Epoch[91] pretrain loss 3.1289 training acc 0.8172
08:43:23 : Epoch [92] with testing accuracy: 0.2321
08:43:24 : Epoch[92] pretrain loss 3.1149 training acc 0.8324
08:43:24 : Epoch [93] with testing accuracy: 0.2591
08:43:25 : Epoch[93] pretrain loss 3.1065 training acc 0.8410
08:43:25 : Epoch [94] with testing accuracy: 0.2452
08:43:26 : Epoch[94] pretrain loss 3.1030 training acc 0.8439
08:43:26 : Epoch [95] with testing accuracy: 0.2394
08:43:27 : Epoch[95] pretrain loss 3.1017 training acc 0.8449
08:43:28 : Epoch [96] with testing accuracy: 0.2410
08:43:29 : Epoch[96] pretrain loss 3.1010 training acc 0.8452
08:43:29 : Epoch [97] with testing accuracy: 0.2514
08:43:30 : Epoch[97] pretrain loss 3.1003 training acc 0.8457
08:43:30 : Epoch [98] with testing accuracy: 0.2550
08:43:31 : Epoch[98] pretrain loss 3.0992 training acc 0.8467
08:43:31 : Epoch [99] with testing accuracy: 0.2673
08:43:32 : Epoch[99] pretrain loss 3.0986 training acc 0.8473
08:43:32 : Epoch [100] with testing accuracy: 0.2677
