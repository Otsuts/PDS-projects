08:39:47 : Epoch[0] pretrain loss 3.8707 training acc 0.2419
08:39:47 : Epoch [1] with testing accuracy: 0.1370
08:39:48 : Epoch[1] pretrain loss 3.6026 training acc 0.4650
08:39:48 : Epoch [2] with testing accuracy: 0.1824
08:39:49 : Epoch[2] pretrain loss 3.3736 training acc 0.6377
08:39:50 : Epoch [3] with testing accuracy: 0.2011
08:39:50 : Epoch[3] pretrain loss 3.2868 training acc 0.6993
08:39:51 : Epoch [4] with testing accuracy: 0.1982
08:39:51 : Epoch[4] pretrain loss 3.2573 training acc 0.7194
08:39:52 : Epoch [5] with testing accuracy: 0.1984
08:39:52 : Epoch[5] pretrain loss 3.2306 training acc 0.7443
08:39:53 : Epoch [6] with testing accuracy: 0.1921
08:39:53 : Epoch[6] pretrain loss 3.2164 training acc 0.7524
08:39:53 : Epoch [7] with testing accuracy: 0.1971
08:39:54 : Epoch[7] pretrain loss 3.1972 training acc 0.7705
08:39:54 : Epoch [8] with testing accuracy: 0.1922
08:39:55 : Epoch[8] pretrain loss 3.1834 training acc 0.7841
08:39:55 : Epoch [9] with testing accuracy: 0.1985
08:39:56 : Epoch[9] pretrain loss 3.1672 training acc 0.7984
08:39:56 : Epoch [10] with testing accuracy: 0.2002
08:39:57 : Epoch[10] pretrain loss 3.1625 training acc 0.8006
08:39:57 : Epoch [11] with testing accuracy: 0.2014
08:39:58 : Epoch[11] pretrain loss 3.1593 training acc 0.8021
08:39:58 : Epoch [12] with testing accuracy: 0.2035
08:39:59 : Epoch[12] pretrain loss 3.1568 training acc 0.8036
08:39:59 : Epoch [13] with testing accuracy: 0.2030
08:40:00 : Epoch[13] pretrain loss 3.1552 training acc 0.8037
08:40:00 : Epoch [14] with testing accuracy: 0.2018
08:40:01 : Epoch[14] pretrain loss 3.1528 training acc 0.8053
08:40:01 : Epoch [15] with testing accuracy: 0.2004
08:40:01 : Epoch[15] pretrain loss 3.1513 training acc 0.8061
08:40:02 : Epoch [16] with testing accuracy: 0.2037
08:40:02 : Epoch[16] pretrain loss 3.1316 training acc 0.8282
08:40:03 : Epoch [17] with testing accuracy: 0.1965
08:40:03 : Epoch[17] pretrain loss 3.1264 training acc 0.8315
08:40:04 : Epoch [18] with testing accuracy: 0.2026
08:40:05 : Epoch[18] pretrain loss 3.1249 training acc 0.8318
08:40:05 : Epoch [19] with testing accuracy: 0.2006
08:40:06 : Epoch[19] pretrain loss 3.1237 training acc 0.8327
08:40:06 : Epoch [20] with testing accuracy: 0.2050
08:40:07 : Epoch[20] pretrain loss 3.1223 training acc 0.8340
08:40:07 : Epoch [21] with testing accuracy: 0.1945
08:40:07 : Epoch[21] pretrain loss 3.1213 training acc 0.8343
08:40:08 : Epoch [22] with testing accuracy: 0.2043
08:40:08 : Epoch[22] pretrain loss 3.1203 training acc 0.8345
08:40:09 : Epoch [23] with testing accuracy: 0.2052
08:40:09 : Epoch[23] pretrain loss 3.1194 training acc 0.8352
08:40:09 : Epoch [24] with testing accuracy: 0.1997
08:40:10 : Epoch[24] pretrain loss 3.1192 training acc 0.8349
08:40:10 : Epoch [25] with testing accuracy: 0.2011
08:40:11 : Epoch[25] pretrain loss 3.1178 training acc 0.8363
08:40:11 : Epoch [26] with testing accuracy: 0.2046
08:40:12 : Epoch[26] pretrain loss 3.1173 training acc 0.8363
08:40:12 : Epoch [27] with testing accuracy: 0.1993
08:40:13 : Epoch[27] pretrain loss 3.1167 training acc 0.8368
08:40:13 : Epoch [28] with testing accuracy: 0.2011
08:40:14 : Epoch[28] pretrain loss 3.1154 training acc 0.8378
08:40:14 : Epoch [29] with testing accuracy: 0.1980
08:40:15 : Epoch[29] pretrain loss 3.1148 training acc 0.8384
08:40:15 : Epoch [30] with testing accuracy: 0.2116
08:40:16 : Epoch[30] pretrain loss 3.1146 training acc 0.8380
08:40:16 : Epoch [31] with testing accuracy: 0.2021
08:40:17 : Epoch[31] pretrain loss 3.1139 training acc 0.8385
08:40:17 : Epoch [32] with testing accuracy: 0.2104
08:40:17 : Epoch[32] pretrain loss 3.1071 training acc 0.8461
08:40:18 : Epoch [33] with testing accuracy: 0.2128
08:40:18 : Epoch[33] pretrain loss 3.0990 training acc 0.8546
08:40:19 : Epoch [34] with testing accuracy: 0.2128
08:40:19 : Epoch[34] pretrain loss 3.0980 training acc 0.8551
08:40:20 : Epoch [35] with testing accuracy: 0.2138
08:40:20 : Epoch[35] pretrain loss 3.0968 training acc 0.8559
08:40:21 : Epoch [36] with testing accuracy: 0.2018
08:40:21 : Epoch[36] pretrain loss 3.0958 training acc 0.8567
08:40:21 : Epoch [37] with testing accuracy: 0.2036
08:40:22 : Epoch[37] pretrain loss 3.0952 training acc 0.8570
08:40:22 : Epoch [38] with testing accuracy: 0.2137
08:40:23 : Epoch[38] pretrain loss 3.0942 training acc 0.8578
08:40:23 : Epoch [39] with testing accuracy: 0.2088
08:40:24 : Epoch[39] pretrain loss 3.0939 training acc 0.8580
08:40:24 : Epoch [40] with testing accuracy: 0.2066
08:40:25 : Epoch[40] pretrain loss 3.0932 training acc 0.8585
08:40:25 : Epoch [41] with testing accuracy: 0.2094
08:40:26 : Epoch[41] pretrain loss 3.0925 training acc 0.8590
08:40:26 : Epoch [42] with testing accuracy: 0.2138
08:40:27 : Epoch[42] pretrain loss 3.0927 training acc 0.8587
08:40:27 : Epoch [43] with testing accuracy: 0.2100
08:40:28 : Epoch[43] pretrain loss 3.0920 training acc 0.8591
08:40:28 : Epoch [44] with testing accuracy: 0.2112
08:40:29 : Epoch[44] pretrain loss 3.0918 training acc 0.8591
08:40:29 : Epoch [45] with testing accuracy: 0.2095
08:40:30 : Epoch[45] pretrain loss 3.0910 training acc 0.8596
08:40:30 : Epoch [46] with testing accuracy: 0.2129
08:40:31 : Epoch[46] pretrain loss 3.0910 training acc 0.8594
08:40:31 : Epoch [47] with testing accuracy: 0.2118
08:40:31 : Epoch[47] pretrain loss 3.0906 training acc 0.8597
08:40:32 : Epoch [48] with testing accuracy: 0.2146
08:40:32 : Epoch[48] pretrain loss 3.0900 training acc 0.8601
08:40:33 : Epoch [49] with testing accuracy: 0.2132
08:40:33 : Epoch[49] pretrain loss 3.0899 training acc 0.8603
08:40:34 : Epoch [50] with testing accuracy: 0.2119
08:40:34 : Epoch[50] pretrain loss 3.0895 training acc 0.8604
08:40:35 : Epoch [51] with testing accuracy: 0.2123
08:40:35 : Epoch[51] pretrain loss 3.0893 training acc 0.8606
08:40:36 : Epoch [52] with testing accuracy: 0.2091
08:40:36 : Epoch[52] pretrain loss 3.0888 training acc 0.8610
08:40:37 : Epoch [53] with testing accuracy: 0.2094
08:40:37 : Epoch[53] pretrain loss 3.0887 training acc 0.8610
08:40:38 : Epoch [54] with testing accuracy: 0.2131
08:40:38 : Epoch[54] pretrain loss 3.0885 training acc 0.8610
08:40:39 : Epoch [55] with testing accuracy: 0.2060
08:40:39 : Epoch[55] pretrain loss 3.0882 training acc 0.8613
08:40:40 : Epoch [56] with testing accuracy: 0.2079
08:40:40 : Epoch[56] pretrain loss 3.0880 training acc 0.8614
08:40:41 : Epoch [57] with testing accuracy: 0.2137
08:40:41 : Epoch[57] pretrain loss 3.0880 training acc 0.8611
08:40:42 : Epoch [58] with testing accuracy: 0.2150
08:40:42 : Epoch[58] pretrain loss 3.0875 training acc 0.8617
08:40:43 : Epoch [59] with testing accuracy: 0.2107
08:40:43 : Epoch[59] pretrain loss 3.0867 training acc 0.8622
08:40:44 : Epoch [60] with testing accuracy: 0.2078
08:40:44 : Epoch[60] pretrain loss 3.0869 training acc 0.8620
08:40:44 : Epoch [61] with testing accuracy: 0.2118
08:40:45 : Epoch[61] pretrain loss 3.0867 training acc 0.8622
08:40:45 : Epoch [62] with testing accuracy: 0.2126
08:40:46 : Epoch[62] pretrain loss 3.0865 training acc 0.8623
08:40:46 : Epoch [63] with testing accuracy: 0.2094
08:40:47 : Epoch[63] pretrain loss 3.0864 training acc 0.8621
08:40:47 : Epoch [64] with testing accuracy: 0.2140
08:40:48 : Epoch[64] pretrain loss 3.0860 training acc 0.8625
08:40:48 : Epoch [65] with testing accuracy: 0.2148
08:40:49 : Epoch[65] pretrain loss 3.0860 training acc 0.8625
08:40:49 : Epoch [66] with testing accuracy: 0.2095
08:40:50 : Epoch[66] pretrain loss 3.0859 training acc 0.8626
08:40:50 : Epoch [67] with testing accuracy: 0.2065
08:40:51 : Epoch[67] pretrain loss 3.0856 training acc 0.8626
08:40:51 : Epoch [68] with testing accuracy: 0.2142
08:40:52 : Epoch[68] pretrain loss 3.0854 training acc 0.8628
08:40:52 : Epoch [69] with testing accuracy: 0.2099
08:40:52 : Epoch[69] pretrain loss 3.0853 training acc 0.8628
08:40:53 : Epoch [70] with testing accuracy: 0.2080
08:40:53 : Epoch[70] pretrain loss 3.0852 training acc 0.8629
08:40:54 : Epoch [71] with testing accuracy: 0.2095
08:40:54 : Epoch[71] pretrain loss 3.0847 training acc 0.8634
08:40:54 : Epoch [72] with testing accuracy: 0.2099
08:40:55 : Epoch[72] pretrain loss 3.0846 training acc 0.8633
08:40:55 : Epoch [73] with testing accuracy: 0.2094
08:40:56 : Epoch[73] pretrain loss 3.0846 training acc 0.8632
08:40:56 : Epoch [74] with testing accuracy: 0.2089
08:40:57 : Epoch[74] pretrain loss 3.0845 training acc 0.8632
08:40:57 : Epoch [75] with testing accuracy: 0.2099
08:40:58 : Epoch[75] pretrain loss 3.0842 training acc 0.8634
08:40:58 : Epoch [76] with testing accuracy: 0.2094
08:40:59 : Epoch[76] pretrain loss 3.0838 training acc 0.8637
08:40:59 : Epoch [77] with testing accuracy: 0.2171
08:41:00 : Epoch[77] pretrain loss 3.0839 training acc 0.8636
08:41:00 : Epoch [78] with testing accuracy: 0.2153
08:41:01 : Epoch[78] pretrain loss 3.0840 training acc 0.8634
08:41:01 : Epoch [79] with testing accuracy: 0.2093
08:41:02 : Epoch[79] pretrain loss 3.0837 training acc 0.8637
08:41:02 : Epoch [80] with testing accuracy: 0.2081
08:41:02 : Epoch[80] pretrain loss 3.0838 training acc 0.8634
08:41:03 : Epoch [81] with testing accuracy: 0.2103
08:41:03 : Epoch[81] pretrain loss 3.0839 training acc 0.8634
08:41:04 : Epoch [82] with testing accuracy: 0.2128
08:41:04 : Epoch[82] pretrain loss 3.0834 training acc 0.8637
08:41:04 : Epoch [83] with testing accuracy: 0.2147
08:41:05 : Epoch[83] pretrain loss 3.0833 training acc 0.8638
08:41:05 : Epoch [84] with testing accuracy: 0.2086
08:41:06 : Epoch[84] pretrain loss 3.0833 training acc 0.8638
08:41:06 : Epoch [85] with testing accuracy: 0.2094
08:41:07 : Epoch[85] pretrain loss 3.0832 training acc 0.8637
08:41:07 : Epoch [86] with testing accuracy: 0.2105
08:41:08 : Epoch[86] pretrain loss 3.0832 training acc 0.8638
08:41:08 : Epoch [87] with testing accuracy: 0.2124
08:41:09 : Epoch[87] pretrain loss 3.0830 training acc 0.8639
08:41:09 : Epoch [88] with testing accuracy: 0.2179
08:41:10 : Epoch[88] pretrain loss 3.0828 training acc 0.8640
08:41:10 : Epoch [89] with testing accuracy: 0.2099
08:41:11 : Epoch[89] pretrain loss 3.0830 training acc 0.8638
08:41:11 : Epoch [90] with testing accuracy: 0.2162
08:41:12 : Epoch[90] pretrain loss 3.0828 training acc 0.8639
08:41:12 : Epoch [91] with testing accuracy: 0.2078
08:41:13 : Epoch[91] pretrain loss 3.0828 training acc 0.8639
08:41:13 : Epoch [92] with testing accuracy: 0.2132
08:41:14 : Epoch[92] pretrain loss 3.0829 training acc 0.8638
08:41:14 : Epoch [93] with testing accuracy: 0.2153
08:41:15 : Epoch[93] pretrain loss 3.0823 training acc 0.8644
08:41:15 : Epoch [94] with testing accuracy: 0.2136
08:41:15 : Epoch[94] pretrain loss 3.0827 training acc 0.8639
08:41:16 : Epoch [95] with testing accuracy: 0.2169
08:41:16 : Epoch[95] pretrain loss 3.0827 training acc 0.8638
08:41:17 : Epoch [96] with testing accuracy: 0.2164
08:41:17 : Epoch[96] pretrain loss 3.0822 training acc 0.8644
08:41:17 : Epoch [97] with testing accuracy: 0.2112
08:41:18 : Epoch[97] pretrain loss 3.0822 training acc 0.8643
08:41:18 : Epoch [98] with testing accuracy: 0.2155
08:41:19 : Epoch[98] pretrain loss 3.0822 training acc 0.8643
08:41:19 : Epoch [99] with testing accuracy: 0.2067
08:41:20 : Epoch[99] pretrain loss 3.0824 training acc 0.8640
08:41:20 : Epoch [100] with testing accuracy: 0.2140
