08:37:30 : Epoch[0] pretrain loss 3.6499 training acc 0.3707
08:37:30 : Epoch [1] with testing accuracy: 0.2809
08:37:31 : Epoch[1] pretrain loss 3.3478 training acc 0.6033
08:37:31 : Epoch [2] with testing accuracy: 0.2830
08:37:32 : Epoch[2] pretrain loss 3.3303 training acc 0.6174
08:37:33 : Epoch [3] with testing accuracy: 0.2440
08:37:34 : Epoch[3] pretrain loss 3.3269 training acc 0.6202
08:37:34 : Epoch [4] with testing accuracy: 0.2910
08:37:35 : Epoch[4] pretrain loss 3.2951 training acc 0.6541
08:37:35 : Epoch [5] with testing accuracy: 0.2713
08:37:36 : Epoch[5] pretrain loss 3.2597 training acc 0.6895
08:37:36 : Epoch [6] with testing accuracy: 0.2548
08:37:37 : Epoch[6] pretrain loss 3.2479 training acc 0.7001
08:37:38 : Epoch [7] with testing accuracy: 0.2541
08:37:39 : Epoch[7] pretrain loss 3.2274 training acc 0.7208
08:37:39 : Epoch [8] with testing accuracy: 0.2524
08:37:40 : Epoch[8] pretrain loss 3.2131 training acc 0.7344
08:37:40 : Epoch [9] with testing accuracy: 0.2409
08:37:41 : Epoch[9] pretrain loss 3.2039 training acc 0.7433
08:37:41 : Epoch [10] with testing accuracy: 0.2477
08:37:42 : Epoch[10] pretrain loss 3.2039 training acc 0.7435
08:37:43 : Epoch [11] with testing accuracy: 0.2550
08:37:44 : Epoch[11] pretrain loss 3.2019 training acc 0.7451
08:37:44 : Epoch [12] with testing accuracy: 0.2659
08:37:45 : Epoch[12] pretrain loss 3.2010 training acc 0.7454
08:37:45 : Epoch [13] with testing accuracy: 0.2665
08:37:46 : Epoch[13] pretrain loss 3.1992 training acc 0.7469
08:37:46 : Epoch [14] with testing accuracy: 0.2303
08:37:47 : Epoch[14] pretrain loss 3.1987 training acc 0.7474
08:37:48 : Epoch [15] with testing accuracy: 0.2525
08:37:49 : Epoch[15] pretrain loss 3.1986 training acc 0.7474
08:37:49 : Epoch [16] with testing accuracy: 0.2477
08:37:50 : Epoch[16] pretrain loss 3.1978 training acc 0.7478
08:37:50 : Epoch [17] with testing accuracy: 0.2402
08:37:51 : Epoch[17] pretrain loss 3.1975 training acc 0.7483
08:37:51 : Epoch [18] with testing accuracy: 0.2507
08:37:52 : Epoch[18] pretrain loss 3.1972 training acc 0.7483
08:37:52 : Epoch [19] with testing accuracy: 0.2514
08:37:53 : Epoch[19] pretrain loss 3.1964 training acc 0.7491
08:37:54 : Epoch [20] with testing accuracy: 0.2522
08:37:55 : Epoch[20] pretrain loss 3.1963 training acc 0.7490
08:37:55 : Epoch [21] with testing accuracy: 0.2449
08:37:56 : Epoch[21] pretrain loss 3.1966 training acc 0.7487
08:37:56 : Epoch [22] with testing accuracy: 0.2440
08:37:57 : Epoch[22] pretrain loss 3.1959 training acc 0.7492
08:37:57 : Epoch [23] with testing accuracy: 0.2458
08:37:58 : Epoch[23] pretrain loss 3.1960 training acc 0.7492
08:37:58 : Epoch [24] with testing accuracy: 0.2444
08:37:59 : Epoch[24] pretrain loss 3.1955 training acc 0.7497
08:37:59 : Epoch [25] with testing accuracy: 0.2433
08:38:00 : Epoch[25] pretrain loss 3.1951 training acc 0.7500
08:38:01 : Epoch [26] with testing accuracy: 0.2477
08:38:02 : Epoch[26] pretrain loss 3.1955 training acc 0.7497
08:38:02 : Epoch [27] with testing accuracy: 0.2439
08:38:03 : Epoch[27] pretrain loss 3.1948 training acc 0.7503
08:38:03 : Epoch [28] with testing accuracy: 0.2481
08:38:04 : Epoch[28] pretrain loss 3.1960 training acc 0.7493
08:38:04 : Epoch [29] with testing accuracy: 0.2435
08:38:05 : Epoch[29] pretrain loss 3.1794 training acc 0.7678
08:38:06 : Epoch [30] with testing accuracy: 0.2032
08:38:07 : Epoch[30] pretrain loss 3.1631 training acc 0.7842
08:38:07 : Epoch [31] with testing accuracy: 0.2212
08:38:08 : Epoch[31] pretrain loss 3.1586 training acc 0.7879
08:38:08 : Epoch [32] with testing accuracy: 0.2247
08:38:09 : Epoch[32] pretrain loss 3.1576 training acc 0.7889
08:38:09 : Epoch [33] with testing accuracy: 0.2361
08:38:10 : Epoch[33] pretrain loss 3.1557 training acc 0.7903
08:38:10 : Epoch [34] with testing accuracy: 0.2390
08:38:11 : Epoch[34] pretrain loss 3.1551 training acc 0.7907
08:38:12 : Epoch [35] with testing accuracy: 0.2462
08:38:13 : Epoch[35] pretrain loss 3.1544 training acc 0.7912
08:38:13 : Epoch [36] with testing accuracy: 0.2279
08:38:14 : Epoch[36] pretrain loss 3.1543 training acc 0.7911
08:38:14 : Epoch [37] with testing accuracy: 0.2337
08:38:15 : Epoch[37] pretrain loss 3.1538 training acc 0.7915
08:38:15 : Epoch [38] with testing accuracy: 0.2318
08:38:16 : Epoch[38] pretrain loss 3.1538 training acc 0.7914
08:38:16 : Epoch [39] with testing accuracy: 0.2364
08:38:17 : Epoch[39] pretrain loss 3.1537 training acc 0.7915
08:38:18 : Epoch [40] with testing accuracy: 0.2330
08:38:19 : Epoch[40] pretrain loss 3.1536 training acc 0.7914
08:38:19 : Epoch [41] with testing accuracy: 0.2337
08:38:20 : Epoch[41] pretrain loss 3.1536 training acc 0.7914
08:38:20 : Epoch [42] with testing accuracy: 0.2371
08:38:21 : Epoch[42] pretrain loss 3.1537 training acc 0.7913
08:38:21 : Epoch [43] with testing accuracy: 0.2339
08:38:22 : Epoch[43] pretrain loss 3.1534 training acc 0.7916
08:38:23 : Epoch [44] with testing accuracy: 0.2386
08:38:24 : Epoch[44] pretrain loss 3.1536 training acc 0.7914
08:38:24 : Epoch [45] with testing accuracy: 0.2376
08:38:25 : Epoch[45] pretrain loss 3.1537 training acc 0.7912
08:38:25 : Epoch [46] with testing accuracy: 0.2309
08:38:26 : Epoch[46] pretrain loss 3.1500 training acc 0.7955
08:38:26 : Epoch [47] with testing accuracy: 0.2123
08:38:27 : Epoch[47] pretrain loss 3.1371 training acc 0.8095
08:38:27 : Epoch [48] with testing accuracy: 0.2366
08:38:28 : Epoch[48] pretrain loss 3.1356 training acc 0.8107
08:38:29 : Epoch [49] with testing accuracy: 0.2244
08:38:30 : Epoch[49] pretrain loss 3.1352 training acc 0.8111
08:38:30 : Epoch [50] with testing accuracy: 0.2313
08:38:31 : Epoch[50] pretrain loss 3.1333 training acc 0.8127
08:38:31 : Epoch [51] with testing accuracy: 0.2407
08:38:32 : Epoch[51] pretrain loss 3.1311 training acc 0.8147
08:38:32 : Epoch [52] with testing accuracy: 0.2468
08:38:33 : Epoch[52] pretrain loss 3.1194 training acc 0.8270
08:38:34 : Epoch [53] with testing accuracy: 0.2631
08:38:35 : Epoch[53] pretrain loss 3.1106 training acc 0.8354
08:38:35 : Epoch [54] with testing accuracy: 0.2568
08:38:36 : Epoch[54] pretrain loss 3.1106 training acc 0.8354
08:38:36 : Epoch [55] with testing accuracy: 0.2491
08:38:37 : Epoch[55] pretrain loss 3.1079 training acc 0.8377
08:38:37 : Epoch [56] with testing accuracy: 0.2608
08:38:38 : Epoch[56] pretrain loss 3.1076 training acc 0.8380
08:38:39 : Epoch [57] with testing accuracy: 0.2527
08:38:40 : Epoch[57] pretrain loss 3.1075 training acc 0.8380
08:38:40 : Epoch [58] with testing accuracy: 0.2522
08:38:41 : Epoch[58] pretrain loss 3.1079 training acc 0.8377
08:38:41 : Epoch [59] with testing accuracy: 0.2509
08:38:42 : Epoch[59] pretrain loss 3.1066 training acc 0.8389
08:38:42 : Epoch [60] with testing accuracy: 0.2430
08:38:43 : Epoch[60] pretrain loss 3.1022 training acc 0.8437
08:38:43 : Epoch [61] with testing accuracy: 0.2549
08:38:44 : Epoch[61] pretrain loss 3.1001 training acc 0.8458
08:38:45 : Epoch [62] with testing accuracy: 0.2529
08:38:46 : Epoch[62] pretrain loss 3.0992 training acc 0.8465
08:38:46 : Epoch [63] with testing accuracy: 0.2538
08:38:47 : Epoch[63] pretrain loss 3.0986 training acc 0.8470
08:38:47 : Epoch [64] with testing accuracy: 0.2678
08:38:48 : Epoch[64] pretrain loss 3.0984 training acc 0.8471
08:38:48 : Epoch [65] with testing accuracy: 0.2280
08:38:49 : Epoch[65] pretrain loss 3.0792 training acc 0.8674
08:38:49 : Epoch [66] with testing accuracy: 0.2600
08:38:50 : Epoch[66] pretrain loss 3.0767 training acc 0.8695
08:38:51 : Epoch [67] with testing accuracy: 0.2546
08:38:52 : Epoch[67] pretrain loss 3.0755 training acc 0.8703
08:38:52 : Epoch [68] with testing accuracy: 0.2594
08:38:53 : Epoch[68] pretrain loss 3.0747 training acc 0.8710
08:38:53 : Epoch [69] with testing accuracy: 0.2424
08:38:54 : Epoch[69] pretrain loss 3.0742 training acc 0.8715
08:38:54 : Epoch [70] with testing accuracy: 0.2692
08:38:55 : Epoch[70] pretrain loss 3.0733 training acc 0.8722
08:38:56 : Epoch [71] with testing accuracy: 0.2586
08:38:57 : Epoch[71] pretrain loss 3.0676 training acc 0.8783
08:38:57 : Epoch [72] with testing accuracy: 0.2788
08:38:58 : Epoch[72] pretrain loss 3.0662 training acc 0.8796
08:38:58 : Epoch [73] with testing accuracy: 0.2539
08:38:59 : Epoch[73] pretrain loss 3.0655 training acc 0.8802
08:38:59 : Epoch [74] with testing accuracy: 0.2603
08:39:00 : Epoch[74] pretrain loss 3.0652 training acc 0.8805
08:39:01 : Epoch [75] with testing accuracy: 0.2498
08:39:02 : Epoch[75] pretrain loss 3.0625 training acc 0.8834
08:39:02 : Epoch [76] with testing accuracy: 0.2581
08:39:03 : Epoch[76] pretrain loss 3.0577 training acc 0.8883
08:39:03 : Epoch [77] with testing accuracy: 0.2409
08:39:04 : Epoch[77] pretrain loss 3.0571 training acc 0.8886
08:39:04 : Epoch [78] with testing accuracy: 0.2618
08:39:05 : Epoch[78] pretrain loss 3.0569 training acc 0.8890
08:39:05 : Epoch [79] with testing accuracy: 0.2613
08:39:06 : Epoch[79] pretrain loss 3.0556 training acc 0.8902
08:39:07 : Epoch [80] with testing accuracy: 0.2578
08:39:08 : Epoch[80] pretrain loss 3.0554 training acc 0.8902
08:39:08 : Epoch [81] with testing accuracy: 0.2583
08:39:09 : Epoch[81] pretrain loss 3.0557 training acc 0.8899
08:39:09 : Epoch [82] with testing accuracy: 0.2558
08:39:10 : Epoch[82] pretrain loss 3.0548 training acc 0.8907
08:39:10 : Epoch [83] with testing accuracy: 0.2558
08:39:11 : Epoch[83] pretrain loss 3.0548 training acc 0.8906
08:39:12 : Epoch [84] with testing accuracy: 0.2596
08:39:13 : Epoch[84] pretrain loss 3.0549 training acc 0.8904
08:39:13 : Epoch [85] with testing accuracy: 0.2472
08:39:14 : Epoch[85] pretrain loss 3.0546 training acc 0.8909
08:39:14 : Epoch [86] with testing accuracy: 0.2558
08:39:15 : Epoch[86] pretrain loss 3.0420 training acc 0.9045
08:39:15 : Epoch [87] with testing accuracy: 0.2488
08:39:16 : Epoch[87] pretrain loss 3.0409 training acc 0.9056
08:39:17 : Epoch [88] with testing accuracy: 0.2659
08:39:18 : Epoch[88] pretrain loss 3.0391 training acc 0.9070
08:39:18 : Epoch [89] with testing accuracy: 0.2576
08:39:19 : Epoch[89] pretrain loss 3.0373 training acc 0.9086
08:39:19 : Epoch [90] with testing accuracy: 0.2680
08:39:20 : Epoch[90] pretrain loss 3.0376 training acc 0.9082
08:39:20 : Epoch [91] with testing accuracy: 0.2764
08:39:21 : Epoch[91] pretrain loss 3.0365 training acc 0.9091
08:39:21 : Epoch [92] with testing accuracy: 0.2467
08:39:22 : Epoch[92] pretrain loss 3.0360 training acc 0.9095
08:39:22 : Epoch [93] with testing accuracy: 0.2514
08:39:23 : Epoch[93] pretrain loss 3.0358 training acc 0.9097
08:39:23 : Epoch [94] with testing accuracy: 0.2458
08:39:24 : Epoch[94] pretrain loss 3.0358 training acc 0.9096
08:39:25 : Epoch [95] with testing accuracy: 0.2474
08:39:26 : Epoch[95] pretrain loss 3.0359 training acc 0.9097
08:39:26 : Epoch [96] with testing accuracy: 0.2498
08:39:27 : Epoch[96] pretrain loss 3.0358 training acc 0.9097
08:39:27 : Epoch [97] with testing accuracy: 0.2449
08:39:28 : Epoch[97] pretrain loss 3.0358 training acc 0.9096
08:39:28 : Epoch [98] with testing accuracy: 0.2464
08:39:29 : Epoch[98] pretrain loss 3.0359 training acc 0.9094
08:39:29 : Epoch [99] with testing accuracy: 0.2476
08:39:30 : Epoch[99] pretrain loss 3.0356 training acc 0.9098
08:39:30 : Epoch [100] with testing accuracy: 0.2466
