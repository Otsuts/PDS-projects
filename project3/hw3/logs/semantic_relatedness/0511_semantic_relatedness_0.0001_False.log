08:35:35 : Epoch[0] pretrain loss 3.8196 training acc 0.3249
08:35:35 : Epoch [1] with testing accuracy: 0.1431
08:35:36 : Epoch[1] pretrain loss 3.4719 training acc 0.5670
08:35:36 : Epoch [2] with testing accuracy: 0.1974
08:35:37 : Epoch[2] pretrain loss 3.2552 training acc 0.7315
08:35:37 : Epoch [3] with testing accuracy: 0.2065
08:35:38 : Epoch[3] pretrain loss 3.1944 training acc 0.7812
08:35:38 : Epoch [4] with testing accuracy: 0.1969
08:35:39 : Epoch[4] pretrain loss 3.1725 training acc 0.7950
08:35:39 : Epoch [5] with testing accuracy: 0.2069
08:35:39 : Epoch[5] pretrain loss 3.1592 training acc 0.8049
08:35:40 : Epoch [6] with testing accuracy: 0.1976
08:35:40 : Epoch[6] pretrain loss 3.1456 training acc 0.8164
08:35:41 : Epoch [7] with testing accuracy: 0.2006
08:35:41 : Epoch[7] pretrain loss 3.1358 training acc 0.8258
08:35:42 : Epoch [8] with testing accuracy: 0.2037
08:35:42 : Epoch[8] pretrain loss 3.1182 training acc 0.8421
08:35:43 : Epoch [9] with testing accuracy: 0.2027
08:35:43 : Epoch[9] pretrain loss 3.1145 training acc 0.8446
08:35:44 : Epoch [10] with testing accuracy: 0.2040
08:35:44 : Epoch[10] pretrain loss 3.1115 training acc 0.8459
08:35:44 : Epoch [11] with testing accuracy: 0.2076
08:35:45 : Epoch[11] pretrain loss 3.1094 training acc 0.8474
08:35:45 : Epoch [12] with testing accuracy: 0.2121
08:35:46 : Epoch[12] pretrain loss 3.1075 training acc 0.8485
08:35:46 : Epoch [13] with testing accuracy: 0.2025
08:35:47 : Epoch[13] pretrain loss 3.1062 training acc 0.8492
08:35:47 : Epoch [14] with testing accuracy: 0.2061
08:35:48 : Epoch[14] pretrain loss 3.1042 training acc 0.8504
08:35:48 : Epoch [15] with testing accuracy: 0.2081
08:35:49 : Epoch[15] pretrain loss 3.1030 training acc 0.8511
08:35:49 : Epoch [16] with testing accuracy: 0.2007
08:35:50 : Epoch[16] pretrain loss 3.1018 training acc 0.8519
08:35:50 : Epoch [17] with testing accuracy: 0.2050
08:35:51 : Epoch[17] pretrain loss 3.1007 training acc 0.8525
08:35:51 : Epoch [18] with testing accuracy: 0.2004
08:35:51 : Epoch[18] pretrain loss 3.0997 training acc 0.8530
08:35:52 : Epoch [19] with testing accuracy: 0.2084
08:35:52 : Epoch[19] pretrain loss 3.0989 training acc 0.8535
08:35:53 : Epoch [20] with testing accuracy: 0.2103
08:35:53 : Epoch[20] pretrain loss 3.0979 training acc 0.8542
08:35:53 : Epoch [21] with testing accuracy: 0.2108
08:35:54 : Epoch[21] pretrain loss 3.0969 training acc 0.8549
08:35:54 : Epoch [22] with testing accuracy: 0.2146
08:35:55 : Epoch[22] pretrain loss 3.0963 training acc 0.8551
08:35:55 : Epoch [23] with testing accuracy: 0.2128
08:35:56 : Epoch[23] pretrain loss 3.0955 training acc 0.8559
08:35:56 : Epoch [24] with testing accuracy: 0.2019
08:35:57 : Epoch[24] pretrain loss 3.0954 training acc 0.8557
08:35:57 : Epoch [25] with testing accuracy: 0.2123
08:35:58 : Epoch[25] pretrain loss 3.0944 training acc 0.8565
08:35:58 : Epoch [26] with testing accuracy: 0.2074
08:35:59 : Epoch[26] pretrain loss 3.0939 training acc 0.8566
08:35:59 : Epoch [27] with testing accuracy: 0.2043
08:36:00 : Epoch[27] pretrain loss 3.0935 training acc 0.8566
08:36:00 : Epoch [28] with testing accuracy: 0.2049
08:36:01 : Epoch[28] pretrain loss 3.0923 training acc 0.8575
08:36:01 : Epoch [29] with testing accuracy: 0.2155
08:36:02 : Epoch[29] pretrain loss 3.0919 training acc 0.8577
08:36:02 : Epoch [30] with testing accuracy: 0.2138
08:36:03 : Epoch[30] pretrain loss 3.0912 training acc 0.8583
08:36:03 : Epoch [31] with testing accuracy: 0.2170
08:36:04 : Epoch[31] pretrain loss 3.0624 training acc 0.8913
08:36:04 : Epoch [32] with testing accuracy: 0.2370
08:36:04 : Epoch[32] pretrain loss 3.0553 training acc 0.8971
08:36:05 : Epoch [33] with testing accuracy: 0.2421
08:36:05 : Epoch[33] pretrain loss 3.0534 training acc 0.8985
08:36:06 : Epoch [34] with testing accuracy: 0.2381
08:36:06 : Epoch[34] pretrain loss 3.0522 training acc 0.8995
08:36:07 : Epoch [35] with testing accuracy: 0.2390
08:36:07 : Epoch[35] pretrain loss 3.0511 training acc 0.8999
08:36:08 : Epoch [36] with testing accuracy: 0.2481
08:36:08 : Epoch[36] pretrain loss 3.0502 training acc 0.9010
08:36:09 : Epoch [37] with testing accuracy: 0.2420
08:36:09 : Epoch[37] pretrain loss 3.0495 training acc 0.9011
08:36:10 : Epoch [38] with testing accuracy: 0.2474
08:36:10 : Epoch[38] pretrain loss 3.0483 training acc 0.9022
08:36:11 : Epoch [39] with testing accuracy: 0.2434
08:36:11 : Epoch[39] pretrain loss 3.0481 training acc 0.9021
08:36:12 : Epoch [40] with testing accuracy: 0.2444
08:36:12 : Epoch[40] pretrain loss 3.0476 training acc 0.9024
08:36:13 : Epoch [41] with testing accuracy: 0.2481
08:36:13 : Epoch[41] pretrain loss 3.0470 training acc 0.9031
08:36:14 : Epoch [42] with testing accuracy: 0.2401
08:36:14 : Epoch[42] pretrain loss 3.0469 training acc 0.9027
08:36:15 : Epoch [43] with testing accuracy: 0.2429
08:36:15 : Epoch[43] pretrain loss 3.0372 training acc 0.9138
08:36:16 : Epoch [44] with testing accuracy: 0.2429
08:36:16 : Epoch[44] pretrain loss 3.0312 training acc 0.9194
08:36:17 : Epoch [45] with testing accuracy: 0.2423
08:36:17 : Epoch[45] pretrain loss 3.0296 training acc 0.9205
08:36:18 : Epoch [46] with testing accuracy: 0.2498
08:36:19 : Epoch[46] pretrain loss 3.0288 training acc 0.9210
08:36:19 : Epoch [47] with testing accuracy: 0.2464
08:36:20 : Epoch[47] pretrain loss 3.0282 training acc 0.9214
08:36:20 : Epoch [48] with testing accuracy: 0.2468
08:36:21 : Epoch[48] pretrain loss 3.0276 training acc 0.9218
08:36:21 : Epoch [49] with testing accuracy: 0.2531
08:36:22 : Epoch[49] pretrain loss 3.0273 training acc 0.9221
08:36:22 : Epoch [50] with testing accuracy: 0.2463
08:36:23 : Epoch[50] pretrain loss 3.0268 training acc 0.9223
08:36:23 : Epoch [51] with testing accuracy: 0.2415
08:36:24 : Epoch[51] pretrain loss 3.0265 training acc 0.9224
08:36:24 : Epoch [52] with testing accuracy: 0.2415
08:36:25 : Epoch[52] pretrain loss 3.0262 training acc 0.9226
08:36:25 : Epoch [53] with testing accuracy: 0.2394
08:36:26 : Epoch[53] pretrain loss 3.0258 training acc 0.9227
08:36:26 : Epoch [54] with testing accuracy: 0.2442
08:36:27 : Epoch[54] pretrain loss 3.0255 training acc 0.9231
08:36:27 : Epoch [55] with testing accuracy: 0.2479
08:36:28 : Epoch[55] pretrain loss 3.0252 training acc 0.9232
08:36:28 : Epoch [56] with testing accuracy: 0.2425
08:36:29 : Epoch[56] pretrain loss 3.0249 training acc 0.9234
08:36:29 : Epoch [57] with testing accuracy: 0.2453
08:36:30 : Epoch[57] pretrain loss 3.0249 training acc 0.9232
08:36:30 : Epoch [58] with testing accuracy: 0.2454
08:36:31 : Epoch[58] pretrain loss 3.0248 training acc 0.9232
08:36:31 : Epoch [59] with testing accuracy: 0.2450
08:36:32 : Epoch[59] pretrain loss 3.0242 training acc 0.9237
08:36:32 : Epoch [60] with testing accuracy: 0.2442
08:36:33 : Epoch[60] pretrain loss 3.0243 training acc 0.9235
08:36:33 : Epoch [61] with testing accuracy: 0.2405
08:36:34 : Epoch[61] pretrain loss 3.0239 training acc 0.9238
08:36:34 : Epoch [62] with testing accuracy: 0.2436
08:36:35 : Epoch[62] pretrain loss 3.0237 training acc 0.9238
08:36:35 : Epoch [63] with testing accuracy: 0.2394
08:36:36 : Epoch[63] pretrain loss 3.0238 training acc 0.9237
08:36:36 : Epoch [64] with testing accuracy: 0.2426
08:36:37 : Epoch[64] pretrain loss 3.0234 training acc 0.9240
08:36:37 : Epoch [65] with testing accuracy: 0.2399
08:36:38 : Epoch[65] pretrain loss 3.0234 training acc 0.9239
08:36:38 : Epoch [66] with testing accuracy: 0.2433
08:36:39 : Epoch[66] pretrain loss 3.0230 training acc 0.9242
08:36:39 : Epoch [67] with testing accuracy: 0.2430
08:36:40 : Epoch[67] pretrain loss 3.0231 training acc 0.9241
08:36:40 : Epoch [68] with testing accuracy: 0.2400
08:36:40 : Epoch[68] pretrain loss 3.0229 training acc 0.9243
08:36:41 : Epoch [69] with testing accuracy: 0.2445
08:36:42 : Epoch[69] pretrain loss 3.0227 training acc 0.9246
08:36:42 : Epoch [70] with testing accuracy: 0.2405
08:36:43 : Epoch[70] pretrain loss 3.0227 training acc 0.9244
08:36:43 : Epoch [71] with testing accuracy: 0.2445
08:36:43 : Epoch[71] pretrain loss 3.0224 training acc 0.9247
08:36:44 : Epoch [72] with testing accuracy: 0.2419
08:36:44 : Epoch[72] pretrain loss 3.0222 training acc 0.9248
08:36:45 : Epoch [73] with testing accuracy: 0.2474
08:36:46 : Epoch[73] pretrain loss 3.0224 training acc 0.9245
08:36:46 : Epoch [74] with testing accuracy: 0.2414
08:36:47 : Epoch[74] pretrain loss 3.0223 training acc 0.9246
08:36:47 : Epoch [75] with testing accuracy: 0.2444
08:36:48 : Epoch[75] pretrain loss 3.0222 training acc 0.9246
08:36:48 : Epoch [76] with testing accuracy: 0.2454
08:36:49 : Epoch[76] pretrain loss 3.0218 training acc 0.9250
08:36:49 : Epoch [77] with testing accuracy: 0.2464
08:36:50 : Epoch[77] pretrain loss 3.0217 training acc 0.9251
08:36:50 : Epoch [78] with testing accuracy: 0.2493
08:36:51 : Epoch[78] pretrain loss 3.0219 training acc 0.9248
08:36:51 : Epoch [79] with testing accuracy: 0.2444
08:36:52 : Epoch[79] pretrain loss 3.0217 training acc 0.9249
08:36:52 : Epoch [80] with testing accuracy: 0.2438
08:36:53 : Epoch[80] pretrain loss 3.0219 training acc 0.9246
08:36:53 : Epoch [81] with testing accuracy: 0.2458
08:36:54 : Epoch[81] pretrain loss 3.0216 training acc 0.9249
08:36:54 : Epoch [82] with testing accuracy: 0.2442
08:36:55 : Epoch[82] pretrain loss 3.0215 training acc 0.9250
08:36:55 : Epoch [83] with testing accuracy: 0.2464
08:36:55 : Epoch[83] pretrain loss 3.0209 training acc 0.9256
08:36:56 : Epoch [84] with testing accuracy: 0.2277
08:36:56 : Epoch[84] pretrain loss 3.0034 training acc 0.9450
08:36:57 : Epoch [85] with testing accuracy: 0.2458
08:36:57 : Epoch[85] pretrain loss 3.0003 training acc 0.9472
08:36:58 : Epoch [86] with testing accuracy: 0.2420
08:36:58 : Epoch[86] pretrain loss 2.9995 training acc 0.9479
08:36:59 : Epoch [87] with testing accuracy: 0.2545
08:36:59 : Epoch[87] pretrain loss 2.9991 training acc 0.9480
08:37:00 : Epoch [88] with testing accuracy: 0.2500
08:37:00 : Epoch[88] pretrain loss 2.9986 training acc 0.9484
08:37:01 : Epoch [89] with testing accuracy: 0.2447
08:37:01 : Epoch[89] pretrain loss 2.9987 training acc 0.9482
08:37:02 : Epoch [90] with testing accuracy: 0.2524
08:37:02 : Epoch[90] pretrain loss 2.9985 training acc 0.9483
08:37:03 : Epoch [91] with testing accuracy: 0.2515
08:37:03 : Epoch[91] pretrain loss 2.9981 training acc 0.9486
08:37:04 : Epoch [92] with testing accuracy: 0.2450
08:37:04 : Epoch[92] pretrain loss 2.9983 training acc 0.9483
08:37:05 : Epoch [93] with testing accuracy: 0.2555
08:37:05 : Epoch[93] pretrain loss 2.9980 training acc 0.9486
08:37:06 : Epoch [94] with testing accuracy: 0.2557
08:37:06 : Epoch[94] pretrain loss 2.9982 training acc 0.9484
08:37:07 : Epoch [95] with testing accuracy: 0.2447
08:37:07 : Epoch[95] pretrain loss 2.9981 training acc 0.9484
08:37:08 : Epoch [96] with testing accuracy: 0.2524
08:37:08 : Epoch[96] pretrain loss 2.9977 training acc 0.9488
08:37:09 : Epoch [97] with testing accuracy: 0.2520
08:37:09 : Epoch[97] pretrain loss 2.9976 training acc 0.9488
08:37:10 : Epoch [98] with testing accuracy: 0.2519
08:37:10 : Epoch[98] pretrain loss 2.9976 training acc 0.9488
08:37:11 : Epoch [99] with testing accuracy: 0.2507
08:37:11 : Epoch[99] pretrain loss 2.9977 training acc 0.9486
08:37:12 : Epoch [100] with testing accuracy: 0.2487
